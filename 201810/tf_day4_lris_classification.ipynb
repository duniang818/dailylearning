{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coco\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r8192/2194 [================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_dataset_url = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "                                           origin=train_dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML at production scale\n",
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\coco\\anaconda3\\lib\\site-packages (18.1)\n"
     ]
    }
   ],
   "source": [
    "# !表示非命令号模式，即在交互式模式下执行命令\n",
    "! python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\nfatal: early EOF\nfatal: The remote end hung up unexpectedly\nfatal: index-pack failed\nerror: RPC failed; curl 18 transfer closed with outstanding read data remaining\n"
     ]
    }
   ],
   "source": [
    "! git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git config --global http.sslVerify false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "sys.path.append(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'official'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-099d99a2096f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwide_deep\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcensus_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwide_deep\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcensus_main\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcensus_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Coco/PycharmProjects/dailylearning/201810/census_data/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'official'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from official.wide_deep import census_dataset\n",
    "from official.wide_deep import census_main\n",
    "\n",
    "census_dataset.download(\"C:/Users/Coco/PycharmProjects/dailylearning/201810/census_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coco\\Documents\\YTOProjects\\AI舆情\\Code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coco\\Anaconda3\\python.exe: Error while finding module specification for 'official.wide_deep.census_main' (ModuleNotFoundError: No module named 'official')\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "!python -m official.wide_deep.census_main --model_type=wide --train_epochs=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data into tensors\n",
    "# input data is specified by using an input function(or input_fn)\n",
    "# for small problems like this, it's easy to make a tf.data.Dataset by slicing the pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_input_function(df, label_key, num_epochs, shuffle, batch_size):\n",
    "  label = df[label_key]\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df),label))\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(10000)\n",
    "\n",
    "  ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = easy_input_function(train_df, label_key='income_bracket', num_epochs=5, shuffle=True, batch_size=10)\n",
    "\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "  print('Some feature keys:', list(feature_batch.keys())[:5])\n",
    "  print()\n",
    "  print('A batch of Ages  :', feature_batch['age'])\n",
    "  print()\n",
    "  print('A batch of Labels:', label_batch )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
